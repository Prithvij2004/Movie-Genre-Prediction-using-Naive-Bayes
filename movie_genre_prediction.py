# -*- coding: utf-8 -*-
"""Movie Genre prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r9lwIM4ulVB5YlEhnO4m2KWwWYZfi5j6
"""

import pandas as pd
import json
import neattext as nt
import neattext.functions as nfx
import re
import nltk
from sklearn.svm import LinearSVC
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import GaussianNB, MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MultiLabelBinarizer
from skmultilearn.problem_transform import BinaryRelevance
from sklearn.multiclass import OneVsRestClassifier
from sklearn.metrics import f1_score
from nltk.corpus import stopwords

file = pd.read_csv("movies_metadata.csv")

movies = pd.DataFrame(file[["imdb_id", "original_title", "overview", "genres"]])

new_genre = []
for i in range(0, len(movies["genres"])):
    new_genre.append([])
    for j in json.loads(movies["genres"][i].replace("\'", "\"")):
        new_genre[i].append(j["name"])

movies['genre_new'] = new_genre
movies = pd.DataFrame(movies)

movies_new = movies[~(movies['genre_new'].str.len() == 0)]


def clean_txt(text):
    text = re.sub("[^a-zA-Z]", " ", str(text))
    text = text.lower()
    return text


movies_new["overview_clean"] = movies_new["overview"].apply(lambda x: clean_txt(x))

movies_new['overview_clean'].apply(lambda x: nt.TextExtractor(x).extract_stopwords())
movies_new['overview_clean'] = movies_new["overview_clean"].apply(nfx.remove_stopwords)

movies_new.head()

nltk.download('stopwords')

stop_words = set(stopwords.words("english"))


def remove_stopwords(text):
    no_stopwords_text = [w for w in text.split() if not w in stop_words]
    return ' '.join(no_stopwords_text)


multilabel_binarizer = MultiLabelBinarizer()
multilabel_binarizer.fit(movies_new["genre_new"])

y = multilabel_binarizer.transform(movies_new["genre_new"])

tfidf = TfidfVectorizer(max_features=15000)

xtrain, xtest, ytrain, ytest = train_test_split(movies_new['overview_clean'], y, train_size=0.8)

xtrain_tfidf = tfidf.fit_transform(xtrain)
xtest_tfidf = tfidf.transform(xtest)

clf = BinaryRelevance(GaussianNB())

clf.fit(xtrain_tfidf, ytrain)


y_pred_prob = clf.predict_proba(xtest_tfidf)
t = 0.3
y_pred_new = (y_pred_prob >= t).astype(int)
print(f1_score(ytest, y_pred_new, average="micro"))


def infer_tags(q):
    q = clean_txt(q)
    q = remove_stopwords(q)
    q_vec = tfidf.transform([q])
    q_pred = clf.predict(q_vec)
    return multilabel_binarizer.inverse_transform(q_pred)


for i in range(5):
    k = xtest.sample(1).index[0]
    print("Movie: ", movies_new['original_title'][k], "\nPredicted genre: ", infer_tags(xtest[k])), print(
        "Actual genre: ", movies_new['genre_new'][k], "\n")
